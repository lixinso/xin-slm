# Production Training Configuration for GPT-OSS MoE Model on Mac Mini
# Optimized for actual training with reasonable compute budget

training:
  # Model configuration
  model_name: "gpt-oss-moe-prod"
  model_variant: "standard"  # Use standard model for good quality
  
  # Data configuration
  dataset_name: "wikitext-2"
  tokenizer_name: "gpt2"
  max_seq_length: 512  # Balanced length for memory efficiency
  
  # Batch configuration - optimized for 16GB Mac Mini
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 16  # Effective batch size = 16
  dataloader_num_workers: 0  # Single-threaded for stability
  
  # Training loop - reasonable for production
  num_train_epochs: 3
  max_steps: -1  # Use full epochs
  
  # Optimizer configuration
  optimizer: "adamw"
  learning_rate: 2e-4  # Slightly lower for stability
  weight_decay: 0.01
  beta1: 0.9
  beta2: 0.95
  epsilon: 1e-8
  max_grad_norm: 1.0
  
  # Learning rate schedule
  lr_scheduler_type: "cosine"
  warmup_steps: 500
  warmup_ratio: 0.1
  
  # Mixed precision training
  fp16: true
  bf16: false
  
  # Memory optimization
  gradient_checkpointing: true
  dataloader_pin_memory: false
  remove_unused_columns: true
  
  # MoE specific training
  moe_aux_loss_coef: 0.02
  moe_z_loss_coef: 0.001
  router_aux_loss_coef: 0.02
  
  # Logging and saving
  logging_steps: 100
  save_steps: 1000
  eval_steps: 500
  save_total_limit: 3
  evaluation_strategy: "steps"
  
  # Output directories
  output_dir: "./checkpoints_prod"
  logging_dir: "./logs_prod"
  
  # Early stopping
  early_stopping_patience: 3
  early_stopping_threshold: 0.01

# Model variants - use standard for production
model_variants:
  standard:
    hidden_size: 768
    intermediate_size: 2048
    num_hidden_layers: 20
    num_attention_heads: 12
    num_key_value_heads: 4
    num_experts: 32
    num_experts_per_tok: 2
    reasoning_effort: "medium"

# Quantization - disable during training, enable for deployment
quantization:
  enable_quantization: false

# Mac Mini optimizations
mac_optimizations:
  device: "mps"
  cpu_fallback: true
  num_workers: 0
  empty_cache_interval: 50  # Clear cache every 50 steps
  use_metal_performance_shaders: true
  
  # Memory management
  max_memory_allocation: "12GB"  # Leave 4GB for system

# Data configuration
data:
  tokenizer_path: "gpt2"
  add_special_tokens: true
  padding_side: "right"
  truncation: true
  min_seq_length: 32
  max_seq_length: 512
  
  # Data filtering and quality
  filter_empty_examples: true

# Monitoring
monitoring:
  use_wandb: false
  use_tensorboard: true
  tensorboard_log_dir: "./logs_prod/tensorboard"
  log_level: "INFO"
  
  # Progress tracking
  disable_tqdm: false
  tqdm_update_interval: 1
  
  # Model logging
  log_model_architecture: true
  log_predictions: false

# Resource monitoring
resource_monitoring:
  monitor_memory: true
  monitor_gpu: true  # MPS monitoring
  memory_threshold: 0.85  # Alert at 85% usage
  monitoring_interval: 100  # Check every 100 steps
  
  # Performance tracking
  track_tokens_per_second: true
  track_loss_progression: true
  save_monitoring_data: true

# Checkpointing
checkpointing:
  resume_from_checkpoint: null  # Set to path to resume
  save_optimizer_states: true
  save_scheduler_states: true
  save_random_states: true
  
  # Model saving
  save_best_model: true
  save_last_model: true
  metric_for_best_model: "eval_loss"
  greater_is_better: false

# Evaluation
evaluation:
  eval_datasets: ["wikitext-2"]
  metrics: ["perplexity", "loss"]
  eval_during_training: true
  eval_at_start: false  # Skip initial eval to save time
  
  # Generation evaluation (expensive, use sparingly)
  eval_generation: false
  generation_max_length: 64
  generation_num_samples: 5

# Debugging and validation
debugging:
  debug_mode: false
  validate_every_n_steps: null
  run_validation_at_start: false
  
  # Memory debugging
  log_memory_usage: true
  memory_profiling_interval: 500
  
  # Gradient debugging
  check_finite_gradients: true
  log_gradient_norms: false

# Performance optimization
performance:
  # Model optimizations
  compile_model: false  # Experimental on Mac
  use_flash_attention: false  # Limited Mac support
  
  # Training optimizations
  pin_memory: false
  non_blocking: false
  
  # Dataloader optimizations
  persistent_workers: false
  prefetch_factor: 2

# Hardware specific settings
hardware:
  # Mac Mini M2/M3 settings
  target_device: "mps"
  cpu_threads: 8
  memory_limit_gb: 12
  
  # Temperature monitoring (Mac specific)
  temperature_threshold: 80  # Celsius
  throttle_on_overheat: true
  
  # Power management
  power_management: true
  low_power_mode: false